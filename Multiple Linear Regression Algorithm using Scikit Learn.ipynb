{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473a5d59",
   "metadata": {},
   "source": [
    " # Multiple Linear Regression Algorithm using Scikit Learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d681b4",
   "metadata": {},
   "source": [
    "__What is Multiple Linear Regression and when should you use it?__\n",
    "\n",
    "Multiple Linear Regression is a supervised learning algorithm used for predicting a continuous outcome variable (also known as the dependent variable) based on multiple independent variables (also known as predictors, features or attributes).\n",
    "\n",
    "Multiple Linear Regression is appropriate when you want to predict a continuous outcome variable based on multiple independent variables. It is a form of linear regression that allows you to model the relationship between multiple independent variables and a single dependent variable.\n",
    "\n",
    "Here are a few examples of when you might use Multiple Linear Regression:\n",
    "\n",
    "- You have a dataset of housing prices and you want to predict the price of a house based on its square footage, number of bedrooms, and location.\n",
    "- You have a dataset of stock prices and you want to predict the future price of a stock based on its past prices, dividends, and trading volume.\n",
    "- You have a dataset of weather data and you want to predict temperature based on humidity, wind speed, and pressure.\n",
    "\n",
    "In general, Multiple Linear Regression is a good choice when you have multiple independent variables and you want to model the relationship between them and the dependent variable. It is important to note that Multiple Linear Regression assumes linear relationship between independent and dependent variables, also it assumes that there is no multicollinearity between independent variables.\n",
    "\n",
    "__What is multicollinearity?__\n",
    "\n",
    "Multicollinearity is a statistical phenomenon that occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. This correlation can cause the coefficient estimates of the independent variables to become unstable and hard to interpret.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacda6b4",
   "metadata": {},
   "source": [
    "__When we shouldn't use Multiple Linear Regression Algorithms?__\n",
    "\n",
    "While Multiple Linear Regression is a widely used and powerful tool for predicting a continuous outcome variable based on multiple independent variables, there are certain situations where it may not be the best choice.\n",
    "\n",
    "Here are a few examples of when you should not use Multiple Linear Regression:\n",
    "\n",
    "- The relationship between the independent and dependent variables is non-linear: Multiple Linear Regression assumes a linear relationship between the independent and dependent variables. If the relationship is non-linear, a non-linear model such as polynomial regression or decision tree may be a better choice.\n",
    "- The dependent variable is binary or categorical: Multiple Linear Regression is designed for predicting continuous outcome variables. If the dependent variable is binary or categorical, a logistic regression or a classification algorithm such as Random Forest or Support Vector Machine would be more appropriate.\n",
    "- There is a high degree of multicollinearity between the independent variables: Multiple Linear Regression assumes that there is no multicollinearity between the independent variables. If multicollinearity is present, it can lead to unreliable and unstable coefficient estimates. In this case, you can try dimensionality reduction techniques or other methods to deal with multicollinearity.\n",
    "- The data has too many missing values: Multiple Linear Regression assumes that the data is complete and that there are no missing values. If the data has too many missing values, it will be difficult to get accurate results with Multiple Linear Regression. In this case, you can use techniques such as imputation, or use a different model such as random forests that can handle missing values.\n",
    "\n",
    "It's important to consider the nature of your data and the assumptions of the model before using Multiple Linear Regression, as using it in an inappropriate situation can lead to inaccurate or unreliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f578ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Important Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\", message=\".*check_inverse*.\", category=UserWarning, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5815d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with 50 rows and 3 columns\n",
    "df = pd.DataFrame({'x1': np.random.randint(25,75,50),\n",
    "                   'x2': np.random.randint(25,75,50),\n",
    "                   'y': np.random.randint(25,75,50)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b5b3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2   y\n",
       "0  43  38  64\n",
       "1  49  70  73\n",
       "2  47  66  73\n",
       "3  38  71  68\n",
       "4  61  39  32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed79b113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2\n",
       "0  43  38\n",
       "1  49  70\n",
       "2  47  66\n",
       "3  38  71\n",
       "4  61  39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop(columns=['y'])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb04853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "1    73\n",
       "2    73\n",
       "3    68\n",
       "4    32\n",
       "Name: y, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['y']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b3b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4390c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multiple linear regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f39f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc8cc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions on the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddcbf5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 305.09\n"
     ]
    }
   ],
   "source": [
    "# Print the mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f95e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Print the R-squared score\n",
    "print(\"R-squared score: %.2f\" % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3ed865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data\n",
    "new_data = [[65,85]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbce9fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [43.07754782]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the model to make predictions on new data\n",
    "predictions = model.predict(new_data)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546270ea",
   "metadata": {},
   "source": [
    "__Multiple Linear Regression Algorithm advantage?__\n",
    "\n",
    "Multiple Linear Regression is a powerful tool that allows you to predict a continuous outcome variable based on multiple independent variables. \n",
    "Here are some of the advantages of using MLR:\n",
    "\n",
    "- Easy to implement: Multiple Linear Regression is relatively simple to implement and understand, making it a popular choice among practitioners.\n",
    "- Flexibility: Multiple Linear Regression can handle multiple independent variables, making it a flexible tool for modeling complex relationships.\n",
    "- Linearity: Multiple Linear Regression assumes a linear relationship between the independent and dependent variables, which can make it easy to interpret the results.\n",
    "- Linearity of features: Multiple Linear Regression assumes that the independent variables are linearly related to the outcome variable. This linearity assumption makes it easy to identify the relationship between the independent variables and the outcome variable.\n",
    "- Efficiency: Multiple Linear Regression is computationally efficient and fast, making it suitable for large datasets.\n",
    "- Model interpretability: Multiple Linear Regression is relatively easy to interpret and the coefficients can be used to estimate the effect of the independent variables on the outcome variable.\n",
    "\n",
    "It's important to note that Multiple Linear Regression assumes that the data is normally distributed, the error term is homoscedastic and independent. Also, it assumes that there is no multicollinearity between the independent variables. These assumptions should be checked before applying MLR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b720c95",
   "metadata": {},
   "source": [
    "__Multiple Linear Regression Algorithm disadvantage?__\n",
    "\n",
    "While  is a powerful tool for predicting a continuous outcome variable based on multiple independent variables, it also has some limitations and potential disadvantages. \n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "- Linearity assumption: Multiple Linear Regression assumes a linear relationship between the independent and dependent variables. If the relationship is non-linear, the model will not be able to capture the true relationship and the results will be inaccurate.\n",
    "- Assumes no multicollinearity: Multiple Linear Regression assumes that there is no multicollinearity between the independent variables. If multicollinearity is present, it can lead to unreliable and unstable coefficient estimates.\n",
    "- Assumes no autocorrelation: Multiple Linear Regression assumes that the errors are independent and identically distributed, if there is autocorrelation in the error term, the results can be misleading.\n",
    "- Assumes no heteroscedasticity: Multiple Linear Regression assumes that the error term has constant variance, if the error term has non-constant variance, the results will be affected.\n",
    "- Assumes no outliers: Multiple Linear Regression assumes that there are no outliers in the data, if outliers are present, they can have a large effect on the results.\n",
    "- Assumes normal distribution of errors: Multiple Linear Regression assumes that the error term is normally distributed, if the error term is not normally distributed, the results can be affected.\n",
    "\n",
    "In addition, Multiple Linear Regression can be sensitive to irrelevant independent variable, and it may not perform well when predictors are correlated. It is important to consider the assumptions of the model and the nature of your data when using Multiple Linear Regression, and to check for potential issues such as multicollinearity, outliers, and non-normality before interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657859f",
   "metadata": {},
   "source": [
    "##### Md. Ashiqur Rahman\n",
    "##### Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
